{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using alpha_vantage because quandl gives only dattsa till March 2018\n",
    "\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import quandl\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from datapackage import Package\n",
    "import urllib.request, json\n",
    "from pymemcache.client import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "support1 = 0\n",
    "support2 = 0\n",
    "resistance1 = 0\n",
    "resistance2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_time_rsi_values(stock_para):\n",
    "    ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    data, meta_data = ts.get_rsi(symbol=stock_para)\n",
    "    return data['RSI'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "def get_earnings_date():\n",
    "    start_date = date.today()\n",
    "    end_date = date.today()+timedelta(5)\n",
    "\n",
    "    list_4_today=list()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        time.sleep(5)\n",
    "        x=single_date.strftime(\"%Y%m%d\")\n",
    "        urlto_search=\"https://api.earningscalendar.net/?date=\"+x\n",
    "        with urllib.request.urlopen(urlto_search) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            for dat in data:\n",
    "                list_4_today.append(dat[\"ticker\"])\n",
    "    return list_4_today\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(symbol_para):\n",
    "    ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    try:\n",
    "        data, meta_data = ts.get_daily_adjusted(symbol=symbol_para, outputsize='full')\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "    myData = data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    myData['20d'] = np.round(myData.Close.rolling(window =20, center = False).mean(),2)\n",
    "    myData['50d'] = np.round(myData.Close.rolling(window =50, center = False).mean(),2)\n",
    "    myData['200d'] = np.round(myData.Close.rolling(window =200, center = False).mean(),2)\n",
    "    return myData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "def SMA_rating(data_simple):\n",
    "#     start_date = date(1998,1,2)\n",
    "#     yesterday = (datetime.now() - timedelta(days=1))\n",
    "#     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "    sma_rating = 0\n",
    "    index = len(data_simple.index)-1\n",
    "    if data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=1\n",
    "    elif data_simple['50d'][index] > data_simple['Close'][index]> data_simple['200d'][index]:\n",
    "        sma_rating=2\n",
    "    elif data_simple['50d'][index] > data_simple['200d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=3\n",
    "    elif data_simple['200d'][index] > data_simple['50d'][index] > data_simple['Close'][index]:\n",
    "        sma_rating=4\n",
    "    elif data_simple['200d'][index]> data_simple['Close'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=5\n",
    "    elif data_simple['Close'][index] > data_simple['200d'][index] > data_simple['50d'][index]:\n",
    "        sma_rating=6\n",
    "    elif data_simple['Close'][index] > data_simple['50d'][index] > data_simple['200d'][index]:\n",
    "        sma_rating=7\n",
    "    return sma_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_rating(data_simple):\n",
    "        data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "        data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "        data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "        data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "        data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "        \n",
    "        #MACD rating\n",
    "        index = len(data_simple)-1\n",
    "        slope = 0\n",
    "        macd_rating = 0\n",
    "        \n",
    "        print(\"Current:\",data_simple['MACD'][index])\n",
    "        print(\"Previous day\",data_simple['MACD'][index-1])\n",
    "        \n",
    "        #Condition for the slope\n",
    "        if((data_simple['MACD'][index] - data_simple['MACD'][index-1])>0):\n",
    "            slope = 1\n",
    "        elif((data_simple['MACD'][index] - data_simple['MACD'][index-1])<0):\n",
    "            slope = -1\n",
    "            \n",
    "        #Condition for the MACD rating\n",
    "        if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "            macd_rating=1\n",
    "        elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "            macd_rating=2\n",
    "        elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "            macd_rating=3\n",
    "        elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "            macd_rating=4\n",
    "        elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "            macd_rating=5\n",
    "        elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "            macd_rating=6\n",
    "        return macd_rating,slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_rsi_values(stock_para):\n",
    "    ts = TechIndicators(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    try:\n",
    "        data, meta_data = ts.get_rsi(symbol=stock_para,interval='1min')\n",
    "    except:\n",
    "        return -1\n",
    "    if(data.empty):\n",
    "        return -1\n",
    "    if(data['RSI'][-1]>70 or data['RSI'][-1]<30):\n",
    "        ret_val = -1\n",
    "    else:\n",
    "        ret_val = 1\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global Declarations\n",
    "\n",
    "reversal = 3 #reversal amount set to 3 as default\n",
    "\n",
    "# (price range, box size)\n",
    "#function will provide box sizes according to traditional method\n",
    "box_ranges = [(.25,.0625),\n",
    "              (1,.125), \n",
    "              (5,.25),\n",
    "              (20,.5),\n",
    "              (100,1),\n",
    "              (200,2),\n",
    "              (500,4),\n",
    "              (1000,5),\n",
    "              (25000,50),\n",
    "              (sys.maxsize,500)]\n",
    "\n",
    "#to check and update box size according to current value of stock\n",
    "def updateBoxSize(price):\n",
    "    for i in range (len(box_ranges)):\n",
    "        if price < box_ranges[i][0]:\n",
    "            return box_ranges[i][1]\n",
    "    return None\n",
    "\n",
    "\n",
    "#using alpha_vantage because quandl gives only data till March 2018\n",
    "\n",
    "#if current trend is x update x column appropriately or move to o column if needed\n",
    "def updateX(item, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list1[-1])\n",
    "   # print(math.floor(item[\"High\"]))\n",
    "    if ( math.floor(item[\"High\"]) >= list1[-1]+box_size ):\n",
    "        list1[-1] = math.floor(item[\"High\"])\n",
    "    #   print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        numberofXBoxes += 1\n",
    "    elif ( math.ceil(item[\"Low\"]) <= list1[-1]-reversal*box_size):\n",
    "        list2.append(math.ceil(item[\"Low\"]))\n",
    "    #   print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        current_trend = 'o'\n",
    "        numberofOBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#if current trend is o update o column appropriately or move to x column if needed\n",
    "def updateO(item, list1, list2, box_size, reversal, current_trend,  numberofXBoxes, numberofOBoxes):\n",
    "    box_size = updateBoxSize(list2[-1])\n",
    "    if ( math.ceil(item[\"Low\"]) <= list2[-1]-box_size ):\n",
    "        list2[-1] = math.ceil(item[\"Low\"])\n",
    "#        print(\"Updated the o value to:\"+str(list2[-1]))\n",
    "        numberofOBoxes += 1\n",
    "    elif ( math.floor(item[\"High\"]) >= list2[-1]+reversal*box_size):\n",
    "        list1.append(math.floor(item[\"High\"]))\n",
    " #       print(\"Updated the x value to:\"+str(list1[-1]))\n",
    "        current_trend = 'x'\n",
    "        numberofXBoxes += 1\n",
    "    return current_trend\n",
    "\n",
    "#create the point and figure from scratch\n",
    "\n",
    "def pointAndFigureCreate(box_size,current_trend, list1, list2, stockhilowdata, numberofXBoxes, numberofOBoxes):\n",
    "    #iterate over each date for the stock and create x or o columns\n",
    "    for index,row in stockhilowdata.iloc[0:].iterrows():\n",
    "        if current_trend == 'x':\n",
    "        #   print(\"The price is:\"+str(row[\"High\"]))\n",
    "            current_trend = updateX(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "        elif current_trend=='o':\n",
    "            current_trend = updateO(row, list1, list2, box_size, reversal, current_trend, numberofXBoxes, numberofOBoxes)\n",
    "          #  print(\"The price is:\"+str(row[\"Low\"]))\n",
    "    return current_trend\n",
    "\n",
    "#check for a continous triple top pattern\n",
    "def continous_triple_top(current_trend, list1):\n",
    "    if(len(list1)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x':\n",
    "        if((list1[-1]> list1[-2]) and (list1[-2] == list1[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "        \n",
    "#check for a continous triple bottom pattern\n",
    "def continous_triple_bottom(current_trend, list2):\n",
    "    if(len(list2)<3):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double top pattern\n",
    "def continous_double_top(current_trend, list1):\n",
    "    if(len(list1)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend=='x':\n",
    "        if(list1[-1]> list1[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "#check for a continous double bottom pattern\n",
    "def continous_double_bottom(current_trend, list2):\n",
    "    if(len(list2)<2):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o':\n",
    "        if(list2[-1]< list2[-2]):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_top(current_trend, list1):\n",
    "    if(len(list1)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'x' and len(list1)>3:\n",
    "        if((list1[-1] > list1[-2]) and (list1[-2] == list1[-3] == list1[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def continous_quadruple_bottom(current_trend, list2):\n",
    "    if(len(list2)<4):\n",
    "        return -1\n",
    "    ret_val = 0\n",
    "    if current_trend == 'o' and len(list2)>3:\n",
    "        if((list2[-1] < list2[-2]) and (list2[-2] == list2[-3] == list2[-4])):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "import itertools\n",
    "def spread_triple_top(current_trend, list1):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'x' and len(list1)>7:\n",
    "        iterprev = 0\n",
    "        resistance = 0\n",
    "        notstt = True\n",
    "        for iter in list1[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                resistance = iter\n",
    "                notstt = False\n",
    "            if resistance!=0 and iter > resistance:\n",
    "                notstt = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstt == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def spread_triple_bottom(current_trend, list2):\n",
    "    ret_val = -1\n",
    "    if current_trend == 'o' and len(list2)>7:\n",
    "        iterprev = 0\n",
    "        support = 0\n",
    "        notstb = True\n",
    "        for iter in list2[-2:-7:1]:\n",
    "            if iterprev == iter:\n",
    "                support = iter\n",
    "                notstb = False\n",
    "            if support!=0 and iter<resistance:\n",
    "                notstb = True\n",
    "                break\n",
    "            iterprev = iter\n",
    "        if(notstb == False):\n",
    "            ret_val = 1\n",
    "        else:\n",
    "            ret_val = -1\n",
    "    return ret_val\n",
    "\n",
    "def get_support_levels(list2):\n",
    "    if(len(list2)>=2):\n",
    "        return list2[-1],list2[-2]\n",
    "    elif (len(list2)==1):\n",
    "        return list2[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "\n",
    "def get_resistance_levels(list1):\n",
    "    if(len(list1)>=2):\n",
    "        return list1[-1],list1[-2]\n",
    "    elif (len(list1)==1):\n",
    "        return list1[-1],0\n",
    "    else:\n",
    "        return 0,0\n",
    "    \n",
    "    \n",
    "def PnFMain(myData):\n",
    "    #list1 stores the highest value of each x column by index\n",
    "    #list2 stores the lowest value of each o column by index\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "\n",
    "    #current_trend stores the value of the most recent trend. we start off with x as default\n",
    "    current_trend = 'x'\n",
    "\n",
    "    numberofXBoxes = 1 # to get number of x boxes in all\n",
    "    numberofOBoxes = 0 # to get number of o boxes in all\n",
    "\n",
    "    #set box size according to price on day 1\n",
    "    box_size = updateBoxSize(myData[\"High\"].iloc[0])\n",
    "    #append price on day 1 to list1 as we start with x\n",
    "    list1.append(math.floor(myData[\"High\"].iloc[0]))\n",
    "    current_trend = pointAndFigureCreate(box_size, current_trend, list1, list2, myData, numberofXBoxes, numberofOBoxes)\n",
    "    ret_val_triple_top = continous_triple_top(current_trend,list1)\n",
    "    ret_val_triple_bottom = continous_triple_bottom(current_trend,list2)\n",
    "    ret_val_double_top = continous_double_top(current_trend,list1)\n",
    "    ret_val_double_bottom = continous_double_bottom(current_trend,list2)\n",
    "    ret_val_quadruple_top = continous_quadruple_top(current_trend,list1)\n",
    "    ret_val_quadruple_bottom = continous_quadruple_bottom(current_trend,list2)\n",
    "    ret_val_spread_triple_top = spread_triple_top(current_trend,list1)\n",
    "    ret_val_spread_triple_bottom = spread_triple_bottom(current_trend,list2)\n",
    "    \n",
    "    global support1\n",
    "    global support2\n",
    "    global resistance1\n",
    "    global resistance2\n",
    "    \n",
    "    support1,support2 = get_support_levels(list2)\n",
    "    resistance1,resistance2 = get_resistance_levels(list1)\n",
    "    \n",
    "    if ret_val_quadruple_top == 1:\n",
    "        return 'a'\n",
    "    elif ret_val_triple_top == 1:\n",
    "        return 'b'\n",
    "    elif ret_val_double_top == 1:\n",
    "        return 'c'\n",
    "    elif ret_val_quadruple_bottom == 1:\n",
    "        return 'd'\n",
    "    elif ret_val_triple_bottom == 1:\n",
    "        return 'e'\n",
    "    elif ret_val_double_bottom == 1:\n",
    "        return 'f'\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_list=list()\n",
    "energy_list=list()\n",
    "industrial_list=list()\n",
    "comm_services_list=list()\n",
    "materials_list=list()\n",
    "health_list=list()\n",
    "consumer_list=list()\n",
    "technology_list=list()\n",
    "consumer_stap_list=list()\n",
    "\n",
    "sector_etf_list=['XLF','XLE','XLI','XLC','XLB','XLV','XLY','XLK','XLP']\n",
    "sector_sma_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_macd_slope={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_pnf_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_rsi_rating={'XLF':0,'XLE':0,'XLI':0,'XLC':0,'XLB':0,'XLV':0,'XLY':0,'XLK':0,'XLP':0}\n",
    "sector_etf_to_names={'XLF':financial_list,'XLE':energy_list,'XLI':industrial_list,'XLC':comm_services_list,'XLB':materials_list,'XLV':health_list,'XLY':consumer_list,'XLK':technology_list,'XLP':consumer_stap_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "package = Package('https://datahub.io/core/s-and-p-500-companies/datapackage.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for resource in package.resources:\n",
    "    if resource.descriptor['datahub']['type'] == 'derived/csv':\n",
    "        my_list=resource.read()\n",
    "df = pd.DataFrame(my_list, columns=['Symbol','Name','Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if df['Sector'][i]=='Industrials':\n",
    "        industrial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Health Care':\n",
    "        health_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Energy':\n",
    "        energy_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Financials':\n",
    "        financial_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Information Technology':\n",
    "        technology_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Discretionary':\n",
    "        consumer_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Materials':\n",
    "        materials_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Telecommunication Services':\n",
    "        comm_services_list.append(df['Symbol'][i])\n",
    "    elif df['Sector'][i]=='Consumer Staples':\n",
    "        consumer_stap_list.append(df['Symbol'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rated_now=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: -2.5702172344478953\n",
      "Previous day -2.801539922471335\n",
      "Current: -1.1601347677328064\n",
      "Previous day -1.2549566981768336\n",
      "Current: -0.11961722189893464\n",
      "Previous day -0.08158058635582677\n",
      "Current: -1.4393983876604324\n",
      "Previous day -1.5060296713094061\n",
      "Current: -0.7185687202308202\n",
      "Previous day -0.6605498146578341\n",
      "Current: -3.7548009657146793\n",
      "Previous day -4.174928979616084\n",
      "Current: 0.2385401374230014\n",
      "Previous day -0.05503951380404715\n",
      "Current: -0.20087312457310702\n",
      "Previous day -0.366700009575581\n",
      "Current: 2.408296280177524\n",
      "Previous day 2.4397146396548237\n",
      "Current: -0.5026017987394198\n",
      "Previous day -0.5781124755528673\n",
      "Current: -0.6045129361085984\n",
      "Previous day -0.7450404498701388\n",
      "Current: -0.939599057741674\n",
      "Previous day -1.296695350582155\n",
      "Data for stock not present in the API\n",
      "Current: -0.5889395302200207\n",
      "Previous day -0.42175669530114845\n",
      "Current: -0.4770178725916949\n",
      "Previous day -0.540343738762715\n",
      "Current: -1.3345659423116274\n",
      "Previous day -1.548042136054022\n",
      "Current: 1.5109231472096525\n",
      "Previous day 1.661778087526514\n",
      "Current: -0.8488533735180397\n",
      "Previous day -0.9992303291036677\n",
      "Current: 1.1892325091414477\n",
      "Previous day 1.2171975682830123\n",
      "Current: 1.3145875747460138\n",
      "Previous day 1.2225586462177773\n",
      "Current: -1.3998133892414657\n",
      "Previous day -1.592799750135093\n",
      "Current: -0.5558663723594464\n",
      "Previous day -0.6832459110943034\n",
      "Current: 3.21357240702028\n",
      "Previous day 3.1547354255876314\n",
      "Current: -2.059703790888925\n",
      "Previous day -2.2712112359224292\n",
      "Current: -1.243089389790569\n",
      "Previous day -1.3628668653798002\n",
      "Current: -1.2219853258488342\n",
      "Previous day -1.3712589116561134\n",
      "Current: -2.7121592314395286\n",
      "Previous day -2.1135248828545627\n",
      "Current: -0.4921149272693697\n",
      "Previous day -0.5811375205861928\n",
      "Current: -1.7168293836107047\n",
      "Previous day -1.790164944857132\n",
      "Current: -1.8880832692648823\n",
      "Previous day -2.274955303310719\n",
      "Current: 0.33322190245039707\n",
      "Previous day 0.37783524800621393\n",
      "Current: -0.14714409624394875\n",
      "Previous day -0.1909032553656811\n",
      "Current: 0.9596733840636915\n",
      "Previous day 0.9286342742809808\n",
      "Current: -0.8189572861303862\n",
      "Previous day -0.8763539150074369\n",
      "Current: -1.038024093793183\n",
      "Previous day -1.3023754487457921\n",
      "Current: -0.2547873932741389\n",
      "Previous day -0.30244883985812265\n",
      "Data for stock not present in the API\n",
      "Current: -2.449385588469916\n",
      "Previous day -2.6046747574141165\n",
      "Current: -1.3439276602928771\n",
      "Previous day -1.4089927989941415\n",
      "Current: -3.995265165037466\n",
      "Previous day -4.2214295308509975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3c17f86f3275>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mmyData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msector_etf_to_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mmyData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mmacd_rating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mslope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMACD_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for sector in sector_etf_list:\n",
    "#     if sector_sma_rating[sector]==1 and sector_macd_rating[sector]==1 and sector_macd_slope[sector]==1:\n",
    "        for i in range(0,len(sector_etf_to_names[sector])):\n",
    "            time.sleep(15)\n",
    "            myData=get_all_data(sector_etf_to_names[sector][i])\n",
    "            time.sleep(15)\n",
    "            if(not myData.empty):\n",
    "                macd_rating,slope = MACD_rating(myData)\n",
    "                df_rated_now= df_rated_now.append({'Stock Symbol':sector_etf_to_names[sector][i], 'SMA':SMA_rating(myData), 'MACD':macd_rating,'MACD Slope':slope, 'PnF':PnFMain(myData), 'RSI':daily_rsi_values(sector_etf_to_names[sector][i]), 'Support1':support1, 'Support2':support2,'Resistance1':resistance1, 'Resistance2':resistance2 }, ignore_index=True)\n",
    "            else:\n",
    "                print('Data for stock not present in the API')\n",
    "        print(df_rated_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rated_now.to_csv('Rated_Stocks_All.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_final_list():\n",
    "    final_list = []\n",
    "    pnf_list = ['a','b','c']\n",
    "    for index,row in df_rated_now.iloc[0:].iterrows():\n",
    "        if row['MACD'] == 1 and row['MACD Slope'] == 1 and row['SMA'] == 1 and row['PnF'] in pnf_list and row['RSI'] == 1:\n",
    "            row_data = {'Symbol':row['Stock Symbol'] , 'Score':row['PnF'], 'Support1':row['Support1'],'Support2':row['Support2'],'Resistance1':row['Resistance1'],'Resistance2':row['Resistance2']}\n",
    "            final_list.append(row_data)\n",
    "    final_df = pd.DataFrame(final_list)\n",
    "    if not final_df.empty:\n",
    "        final_df['SymbolKey'] = final_df['Symbol']\n",
    "        final_df.set_index('SymbolKey', inplace = True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_price(stock_list):\n",
    "    close_price = list()\n",
    "    for row in stock_list.iterrows():\n",
    "        symbol = row[1]['Symbol']\n",
    "        print(\"Symbol is:\", symbol)\n",
    "        ts = TimeSeries(key='N2C8EGBURO9OUD1E', output_format='pandas',indexing_type='date')\n",
    "        try:\n",
    "            data, meta_data = ts.get_daily_adjusted(symbol=symbol, outputsize='full')\n",
    "            myData = data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "            close_price.append(myData['Close'].iloc[-1])\n",
    "        except:\n",
    "            close_price.append(-1)\n",
    "        time.sleep(15)\n",
    "    stock_list['Close Price']=close_price\n",
    "    return stock_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn_for_earnings():\n",
    "    start_date = date.today()\n",
    "    end_date = date.today()+timedelta(30)\n",
    "\n",
    "    earnings_date_list=list()\n",
    "    for single_date in daterange(start_date, end_date):\n",
    "        time.sleep(5)\n",
    "        x=single_date.strftime(\"%Y%m%d\")\n",
    "        urlto_search=\"https://api.earningscalendar.net/?date=\"+x\n",
    "        with urllib.request.urlopen(urlto_search) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            year=int(x[0:4])\n",
    "            month=int(x[4:6])\n",
    "            day=int(x[6:8])\n",
    "            for dat in data:   \n",
    "                d0 = date.today()\n",
    "                d1 = date(year, month, day)\n",
    "                delta = d1 - d0\n",
    "                earnings_date_list.append([dat[\"ticker\"],x,delta.days])\n",
    "                \n",
    "    new_df=pd.DataFrame(columns=['Symbol','EarningsDate','Days to Earnings'])\n",
    "    for ea in earnings_date_list:\n",
    "        new_df=new_df.append({'Symbol':ea[0],'EarningsDate':ea[1],'Days to Earnings':ea[2]},ignore_index=True)\n",
    "#     new_df.to_csv('earnings_warnings2.csv', index=False)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_five_global = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings List:     Symbol EarningsDate Days to Earnings\n",
      "0      SNP     20190902                0\n",
      "1    UNICY     20190902                0\n",
      "2    GLPEY     20190902                0\n",
      "3    COVTY     20190902                0\n",
      "4    MDOMF     20190902                0\n",
      "5     SSKN     20190902                0\n",
      "6     RMED     20190902                0\n",
      "7    PQUEQ     20190902                0\n",
      "8     COUP     20190903                1\n",
      "9     EGAN     20190903                1\n",
      "10     HQY     20190903                1\n",
      "11    CONN     20190903                1\n",
      "12     GSM     20190903                1\n",
      "13   SSNLF     20190903                1\n",
      "14     YRD     20190903                1\n",
      "15   DNZOY     20190903                1\n",
      "16   LGRVF     20190903                1\n",
      "17   ASEKY     20190903                1\n",
      "18    NSSC     20190903                1\n",
      "19    TUFN     20190903                1\n",
      "20    PRED     20190903                1\n",
      "21    CSTL     20190903                1\n",
      "22    GWGH     20190903                1\n",
      "23    CTST     20190903                1\n",
      "24      SB     20190903                1\n",
      "25    CMFN     20190903                1\n",
      "26     AMR     20190903                1\n",
      "27    YOGA     20190903                1\n",
      "28    CLDR     20190904                2\n",
      "29    PANW     20190904                2\n",
      "..     ...          ...              ...\n",
      "191  HNNMY     20190925               23\n",
      "192    FUL     20190925               23\n",
      "193    WOR     20190925               23\n",
      "194    ATU     20190925               23\n",
      "195    OMN     20190925               23\n",
      "196   NTWK     20190925               23\n",
      "197  HEOFF     20190925               23\n",
      "198     MU     20190926               24\n",
      "199    RAD     20190926               24\n",
      "200    MKC     20190926               24\n",
      "201    ACN     20190926               24\n",
      "202    CAG     20190926               24\n",
      "203    CCL     20190926               24\n",
      "204    FGP     20190926               24\n",
      "205    FDS     20190926               24\n",
      "206    CMD     20190926               24\n",
      "207   PRGS     20190926               24\n",
      "208   SCHL     20190926               24\n",
      "209   ANGO     20190926               24\n",
      "210   CAMP     20190926               24\n",
      "211   BSET     20190926               24\n",
      "212   PSTI     20190926               24\n",
      "213   DYNT     20190926               24\n",
      "214     BB     20190927               25\n",
      "215    MTN     20190927               25\n",
      "216   SFIX     20191001               29\n",
      "217     LW     20191001               29\n",
      "218   PAYX     20191001               29\n",
      "219     NG     20191001               29\n",
      "220   LNDC     20191001               29\n",
      "\n",
      "[221 rows x 3 columns]\n",
      "Stock List Before:            Resistance1  Resistance2 Score  Support1  Support2 Symbol\n",
      "SymbolKey                                                           \n",
      "CINF             112.0         87.0     c      83.0      72.0   CINF\n",
      "CME              216.0        204.0     c     192.0     172.0    CME\n",
      "Symbol is: CINF\n",
      "Symbol is: CME\n",
      "The value of delta is 0.639\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.639\n",
      "Got empty\n",
      "The value of delta is 0.808\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.808\n",
      "The value of delta is 0.856\n",
      "The otm limit is 0.85\n",
      "The value of delta is 0.8009999999999999\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.8009999999999999\n",
      "The value of delta is 0.888\n",
      "The otm limit is 0.85\n",
      "The value of delta is 0.753\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.753\n",
      "The value of delta is 0.6739999999999999\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.6739999999999999\n",
      "The value of delta is 0.573\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.573\n",
      "The value of delta is 0.725\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.725\n",
      "The value of delta is 0.806\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.806\n",
      "The value of delta is 0.625\n",
      "The otm limit is 0.85\n",
      "The value of delta 0.625\n",
      "Got empty\n",
      "The value of delta is 0.888\n",
      "The otm limit is 0.9\n",
      "The value of delta 0.888\n",
      "The value of delta is 0.806\n",
      "The otm limit is 0.9\n",
      "The value of delta 0.806\n",
      "Got empty\n",
      "No contracts available in the moderate criteria\n",
      "Got empty\n",
      "Got empty\n",
      "No contracts available in the safe criteria\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime  \n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Following code makes relevant tokens necessary to conduct TD ameritrade activities on behalf of my account\n",
    "# Note refresh token is valid for 90 days. It is used to generate auth token which is only valid for 30 mins\n",
    "def get_auth_token():\n",
    "    refresh_token = 'KNFyYv+KGMJ+nKBpcwa4rtmncy8+yBJajF/Huc6zfFJhoc440S5jKMWbEk1P7y7LGbLXs+hICnPoOEPoU+aMa/fljcHtHs4yzynVECMaHTlIRmg8+eaLh9Vc+WEKz00WI5pi+vR28u4ab79tMl/SytQeLvyH9P0y6eT9snxhZQ5clTdF6O/0NQYUTs3KZiAZpGUvjWO7YPmuv+BM+WspLwgZsXiI6pYa8nJwpiDJ6uoicJQApUJrSoAFAdKwC6aBs+BF8M/81Wt6iEpsKTnknEhldLa4FcXmsEhHIbVQBDyIfNMt/UEmGd3lTyuG5MSWz1bkcjv6mKTCE8Ho838HnXPx7KeLl3eKOTNtBaK08wQF65d95iBGs3OrzKu4VITJIyk1VAK0SIQcION4SDJDLqSjABdVEuqyfdBe5yKqXFRijgF+7YPvoiCxNXR100MQuG4LYrgoVi/JHHvlaq7yrxEX7I4pUK6eaG0sXBCazdygpsxc8yaE3S0IjUayIh2GhptY3kAo3ZCmP7TnwsQiHPZhfkNtYcJmnWbAdI/4O1Gqk+mqnHIujHtpFPIFaWaZa4/EHk8/zTXzkqGcCWSmjjjcxMNyGm11jHLnYd6egEDLpxeYS+bkb7UYGLn0aNeIExtYq5IjZeP63XRbpflGtiBLNgGmLlJfZg0S4RABknkp9HIicMhRZgFAnqr71FdXP4aGgbh15sRc8WOSlXWoo980e5CS8on+LEpvu8FGQAlmQj0dTs6bjXa7WAOLxvxHIN+k1dnPFkKgJlIMLnMyIVJpY2kE/todzRqo4QAeUb/ualjJvaiiPsGv0cNhgvpCRUBrNjmNfv5gLdz/4KIQDBy3g3jdYrWzFCNH54IS9cnqdmBfi/6b5bs1AA6AhC3kAqxMIE8IXI8=212FD3x19z9sWBHDJACbC00B75E'\n",
    "    auth_params = {'grant_type':'refresh_token', 'refresh_token':refresh_token, 'client_id':'MIC02PQTCV9GGVDGI8OTPTGQWESRT0FA@AMER.OAUTHAP'}\n",
    "    auth_api_url = 'https://api.tdameritrade.com/v1/oauth2/token'\n",
    "    return \"Bearer \"+ requests.post(auth_api_url, data=auth_params).json()['access_token']\n",
    "\n",
    "\n",
    "# Following code will get the option chain data using the authorized token\n",
    "# Parameters: call_or_put: 'CALL'/'PUT'; symbol: string with stock symbol from passed in stock list\n",
    "def get_raw_option_data(call_or_put, symbol):\n",
    "    url = 'https://api.tdameritrade.com/v1/marketdata/chains'\n",
    "    strike_count = '500' #need to figure out how to get ALL or just use an arbitraliy huge num\n",
    "    strategy = 'SINGLE'\n",
    "    authorization_header = {'Authorization': get_auth_token()}\n",
    "    pay = {'symbol':symbol,'strikeCount':strike_count , 'strategy':strategy}\n",
    "    if call_or_put == \"CALL\":\n",
    "        return [requests.get(url, params = pay, headers = authorization_header).json()['callExpDateMap'], requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "    elif call_or_put == \"PUT\":\n",
    "        return [requests.get(url, params = pay, headers = authorization_header).json()['putExpDateMap'], requests.get(url, params = pay, headers = authorization_header).json()['underlyingPrice']]\n",
    "\n",
    "\n",
    "\n",
    "# Following code does the filtering of the options data based on our chosen parameters\n",
    "def processing(symbol,supp1,supp2, params, call_or_put):\n",
    "    data = get_raw_option_data(call_or_put, symbol)\n",
    "    agg_data = {}\n",
    "    date_keys = []\n",
    "    for (k,v) in data[0].items():\n",
    "        date_keys.append([k,list(v.keys())])\n",
    "        agg_data[k] = v\n",
    "        \n",
    "    #If there is no data regarding some symbol in API then just return an empty dataframe\n",
    "    if not date_keys:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    target_list = []\n",
    "    stock_price = data[1]\n",
    "    \n",
    "    if call_or_put == \"CALL\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price < params['%OTM_lim']: # Percent OTM Requirement!\n",
    "                    continue\n",
    "                if 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'] < params['prob_OTM_lim']: # Prob OTM Requirement!\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "                # construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock': symbol,\n",
    "                         'contract': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'],\n",
    "                         '% OTM': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price) / stock_price,\n",
    "                         'cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'])/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'max_cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']+((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*2,\n",
    "                         'annual_return': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'] * 365 * 100)/((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) * (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])),\n",
    "                         'btwn_supports':support}\n",
    "                target_list.append(target)\n",
    "    elif call_or_put == \"PUT\":\n",
    "        for i in range(0,len(date_keys)):\n",
    "            for j in range(0, len(date_keys[i][1])):\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] < params['days_min'] or agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'] > params['days_max']: # Days to Expiration Requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] < params['bid_min']: # Min/Max Bid requirement!\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['totalVolume'] < params['min_vol']: # Min/Max Volume Requirement!\n",
    "                    continue\n",
    "                if (stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']) / stock_price < params['%OTM_lim']: # Percent OTM Requirement!\n",
    "                    continue\n",
    "                delt = 1 + agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']\n",
    "                print(\"The value of delta is\", delt)\n",
    "                print(\"The otm limit is\", params['prob_OTM_lim'])\n",
    "                if delt < params['prob_OTM_lim']: # Prob OTM Requirement!      + or -???\n",
    "                    print(\"The value of delta\", delt)\n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']) < params['cov_ret']: # Covered return Requirement! \n",
    "                    continue\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*-2 < params['prob_touch']: # Probability of touching parameter      + or - ???\n",
    "                    continue\n",
    "                support = 0\n",
    "                if agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']<supp1 and agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']>supp2:\n",
    "                    support = 1\n",
    "#Commented code checks for 24% annual return. If required in future\n",
    "#                 value = (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid']*365*100)/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice']*agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'])\n",
    "#                 if value<15:\n",
    "#                     continue\n",
    "    \n",
    "                # Construct a dictionary object characteristics we want and append to list\n",
    "                target = {'stock':symbol,\n",
    "                         'contract': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['symbol'],\n",
    "                         'strike_price':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'stock_price':stock_price,\n",
    "                         'days_to_exp':agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration'],\n",
    "                         'bid': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'],\n",
    "                         'ask': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['ask'],\n",
    "                         'last': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['last'],\n",
    "                         'prob_OTM': 1 + agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta'], # + or - ???\n",
    "                         '% OTM': stock_price/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'],\n",
    "                         'cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']-((agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] - stock_price)/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'max_cov_ret': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['mark']+((stock_price - agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'])/stock_price)*(365/agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'prob_touch': agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['delta']*2,\n",
    "                         'annual_return': (agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['bid'] * 365 * 100)/(agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['strikePrice'] * agg_data[date_keys[i][0]][date_keys[i][1][j]][0]['daysToExpiration']),\n",
    "                         'btwn_supports': support}# + or - ???\n",
    "                \n",
    "#                 print(\"The value of accepted delta\",target['prob_OTM'])\n",
    "                target_list.append(target)\n",
    "    df = pd.DataFrame(target_list)\n",
    "    if(df.empty):\n",
    "        print('Got empty')\n",
    "        return df\n",
    "    df = df.set_index('contract', drop = False)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Following function returns price data for a stock which can be used to construct a P&F chart\n",
    "def return_candle_data(symbol):\n",
    "    candle_url = 'https://api.tdameritrade.com/v1/marketdata/'+symbol+'/pricehistory'\n",
    "    candle_header = {'Authorization': get_auth_token()}\n",
    "    # Vary the properties below depending on how often you want the data\n",
    "    # Ideally, we want to set up a web socket to continuously stream this data?\n",
    "    period_type = 'day'\n",
    "    period = 2\n",
    "    freq_type = 'minute'\n",
    "    freq = 1\n",
    "    candle_payload = {'periodType': period_type, 'period': period, 'frequencyType': freq_type, 'frequency': freq}\n",
    "    raw_candle_data = requests.get(candle_url, params = candle_payload, headers = candle_header).json()\n",
    "    df = pd.DataFrame(raw_candle_data['candles'])\n",
    "    return df\n",
    "\n",
    "# Get the relevant options after proving stock symbol and parameter list for filtering. \n",
    "def main():\n",
    "    stock_list = get_final_list() # Need to populate this array with stock list we derive from technical indicators\n",
    "    earnings_df = warn_for_earnings()\n",
    "    print('Earnings List:',earnings_df)\n",
    "    print('Stock List Before:', stock_list)\n",
    "    \n",
    "    stock_list.to_csv('Stock_List.csv')\n",
    "    stock_list.to_csv(datetime.today().strftime('%Y-%m-%d')+'.csv')\n",
    "    stock_list.sort_values(by=['Score'], ascending = False)    \n",
    "    stock_list = get_close_price(stock_list)\n",
    "\n",
    "    safe_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, 'max_vol': 1000000000, '%OTM_lim': 0.10, 'prob_OTM_lim': 0.95, 'cov_ret': 0.01, 'prob_touch': 0.01}\n",
    "    mod_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, 'max_vol': 1000000000, '%OTM_lim': 0.05, 'prob_OTM_lim': 0.90, 'cov_ret': 0.01, 'prob_touch': 0.01}\n",
    "    risky_put_parameters = {'days_min': 1, 'days_max': 60, 'bid_min':0.25, 'bid_max': 10000000, 'min_vol': 5, 'max_vol': 1000000000, '%OTM_lim': 0.0, 'prob_OTM_lim': 0.85, 'cov_ret': 0.01, 'prob_touch': 0.01}\n",
    "    \n",
    "    df_top_five_all =  pd.DataFrame()\n",
    "    for row in stock_list.iterrows():\n",
    "        item = row[1]['Symbol']\n",
    "        supp1 = row[1]['Support1']\n",
    "        supp2 = row[1]['Support2']\n",
    "        df = processing(item,supp1,supp2, risky_put_parameters, \"PUT\")\n",
    "        if(not df.empty):\n",
    "            df_top_five = df.sort_values(by=['annual_return'], ascending=False)\n",
    "            df_top_five = df_top_five.head(5)\n",
    "            if df_top_five_all.empty:\n",
    "                df_top_five_all = df_top_five\n",
    "            else:\n",
    "                df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "                \n",
    "    if(not df_top_five_all.empty):\n",
    "        df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_return'], ascending=[False,True,False])\n",
    "        df_top_five_all['Days to Earnings'] = 'Not Near'\n",
    "        for row in df_top_five_all.iterrows():\n",
    "            if row[1]['stock'] in earnings_df['Symbol']:\n",
    "                d_days=int(warn_pd.loc[earnings_df['Symbol'] == str(row['symbol'])]['Days to Earnings'])-row['days_to_exp'][i]   \n",
    "                if d_days>0:\n",
    "                    if d_days<10:\n",
    "                        df_top_five_all.drop(row, axis=0)\n",
    "                    else:\n",
    "                        row['Days to Earnings']=d_days\n",
    "        df_top_five_all.to_csv('ALL_Stocks_Risky.csv')\n",
    "    else:\n",
    "        print(\"No contracts available in the risky criteria\")\n",
    "    \n",
    "    df_top_five_all = pd.DataFrame()\n",
    "    for row in stock_list.iterrows():\n",
    "        item = row[1]['Symbol']\n",
    "        supp1 = row[1]['Support1']\n",
    "        supp2 = row[1]['Support2']\n",
    "        df = processing(item,supp1,supp2, mod_put_parameters, \"PUT\")\n",
    "        if(not df.empty):\n",
    "            print('Processing for stock:',item)\n",
    "            df_top_five = df.sort_values(by=['annual_return'], ascending=False)\n",
    "            df_top_five = df_top_five.head(5)\n",
    "            if df_top_five_all.empty:\n",
    "                df_top_five_all = df_top_five\n",
    "            else:\n",
    "                df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "    if(not df_top_five_all.empty):\n",
    "        df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_return'], ascending=[False,True,False])\n",
    "        df_top_five_all['Days to Earnings'] = 'Not Near'\n",
    "        for row in df_top_five_all.iterrows():\n",
    "            if row[1]['stock'] in earnings_df['Symbol']:\n",
    "                d_days=int(warn_pd.loc[earnings_df['Symbol'] == str(row['symbol'])]['Days to Earnings'])-row['days_to_exp'][i]   \n",
    "                if d_days>0:\n",
    "                    if d_days<10:\n",
    "                        df_top_five_all.drop(row, axis=0)\n",
    "                    else:\n",
    "                        row['Days to Earnings']=d_days\n",
    "\n",
    "        df_top_five_all.to_csv('ALL_Stocks_Mod.csv')\n",
    "    else:\n",
    "        print(\"No contracts available in the moderate criteria\")\n",
    "        \n",
    "    df_top_five_all = pd.DataFrame()\n",
    "    for row in stock_list.iterrows():\n",
    "        item = row[1]['Symbol']\n",
    "        supp1 = row[1]['Support1']\n",
    "        supp2 = row[1]['Support2']\n",
    "        df = processing(item,supp1,supp2, safe_put_parameters, \"PUT\")\n",
    "        if(not df.empty):\n",
    "            print('Processing for stock:',item)\n",
    "            df_top_five = df.sort_values(by=['annual_return'], ascending=False)\n",
    "            df_top_five = df_top_five.head(5)\n",
    "            if df_top_five_all.empty:\n",
    "                df_top_five_all = df_top_five\n",
    "            else:\n",
    "                df_top_five_all = df_top_five_all.append(df_top_five)\n",
    "    if(not df_top_five_all.empty):\n",
    "        df_top_five_all = df_top_five_all.sort_values(by=['btwn_supports','stock','annual_return'], ascending=[False,True,False]) \n",
    "\n",
    "        df_top_five_all['Days to Earnings'] = 'Not Near'\n",
    "        for row in df_top_five_all.iterrows():\n",
    "            if row[1]['stock'] in earnings_df['Symbol']:\n",
    "                d_days=int(warn_pd.loc[earnings_df['Symbol'] == str(row['symbol'])]['Days to Earnings'])-row['days_to_exp'][i]   \n",
    "                if d_days>0:\n",
    "                    if d_days<10:\n",
    "                        df_top_five_all.drop(row, axis=0)\n",
    "                    else:\n",
    "                        row['Days to Earnings']=d_days\n",
    "        df_top_five_all.to_csv('ALL_Stocks_Safe.csv')                 \n",
    "\n",
    "        print('Check the new csv')\n",
    "        print('Processing complete!')\n",
    "    else:\n",
    "        print(\"No contracts available in the safe criteria\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Scope Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope):\n",
    "    \n",
    "    ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas',indexing_type='date')\n",
    "    data, meta_data = ts.get_daily_adjusted(symbol=etf, outputsize='full')\n",
    "    myData = data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    #print(myData.head())\n",
    "    myDataSimple=myData[['Close']].copy()\n",
    "    myDataSimple['20d'] = np.round(myDataSimple.Close.rolling(window =20, center = False).mean(),2)\n",
    "    myDataSimple['50d'] = np.round(myDataSimple.Close.rolling(window =50, center = False).mean(),2)\n",
    "    myDataSimple['200d'] = np.round(myDataSimple.Close.rolling(window =200, center = False).mean(),2)\n",
    "    sma_rating_today=SMA_rating(myDataSimple)\n",
    "    macd_rating_today,slope=MACD_rating(myDataSimple)\n",
    "    time.sleep(12)\n",
    "    return sma_rating_today,macd_rating_today,slope   \n",
    "\n",
    "\n",
    "for etf in sector_etf_list:\n",
    "    #print(etf)\n",
    "    sector_sma_rating[etf],sector_macd_rating[etf],sector_macd_slope[etf]=get_sector_ratings(etf,sector_sma_rating,sector_macd_rating,sector_macd_slope)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intra_day_data():\n",
    "    ts = TimeSeries(key='ZSAE2CXUXOLE67NH', output_format='pandas')\n",
    "    intra_day_data, meta_data = ts.get_intraday(symbol='MSFT',interval='1min', outputsize='full')\n",
    "    intra_day_data = intra_day_data.rename(index=str, columns={\"2. high\": \"High\", \"3. low\": \"Low\",\"4. close\":\"Close\"})\n",
    "    intra_day_data['20m'] = np.round(intra_day_data.Close.rolling(window =20, center = False).mean(),2)\n",
    "    intra_day_data['50m'] = np.round(intra_day_data.Close.rolling(window =50, center = False).mean(),2)\n",
    "    intra_day_data['200m'] = np.round(intra_day_data.Close.rolling(window =200, center = False).mean(),2)\n",
    "    return intra_day_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA rating\n",
    "def SMA_rating_intra_day(data_simple):\n",
    "#     start_date = date(1998,1,2)\n",
    "#     yesterday = (datetime.now() - timedelta(days=1))\n",
    "#     end_date = date(yesterday.year,yesterday.month,yesterday.day)\n",
    "    sma_rating = 0\n",
    "    sma_ratings = []\n",
    "    for index,val in enumerate(data_simple['Close']):\n",
    "        if data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "            sma_rating=1\n",
    "        elif data_simple['50m'][index] > data_simple['Close'][index]> data_simple['200m'][index]:\n",
    "            sma_rating=2\n",
    "        elif data_simple['50m'][index] > data_simple['200m'][index] > data_simple['Close'][index]:\n",
    "            sma_rating=3\n",
    "        elif data_simple['200m'][index] > data_simple['50m'][index] > data_simple['Close'][index]:\n",
    "            sma_rating=4\n",
    "        elif data_simple['200m'][index]> data_simple['Close'][index] > data_simple['50m'][index]:\n",
    "            sma_rating=5\n",
    "        elif data_simple['Close'][index] > data_simple['200m'][index] > data_simple['50m'][index]:\n",
    "            sma_rating=6\n",
    "        elif data_simple['Close'][index] > data_simple['50m'][index] > data_simple['200m'][index]:\n",
    "            sma_rating=7\n",
    "        sma_ratings.append(sma_rating)\n",
    "    return sma_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MACD_rating_intra_day(data_simple):\n",
    "        data_simple['26 ema']=data_simple.Close.ewm(span=26).mean()\n",
    "        data_simple['12 ema']=data_simple.Close.ewm(span=12).mean()\n",
    "        data_simple['9 ema']=data_simple.Close.ewm(span=9).mean()\n",
    "        data_simple['MACD'] = (data_simple['12 ema'] - data_simple['26 ema'])\n",
    "        data_simple['signal_line']=data_simple.MACD.ewm(span=9).mean()\n",
    "        data_simple['hist']=(data_simple['MACD']-data_simple['signal_line'])\n",
    "        #MACD rating\n",
    "        index = len(data_simple.index)-1\n",
    "        macd_rating = 0\n",
    "        macd_ratings = []\n",
    "        for index,val in enumerate(data_simple['Close']):\n",
    "            if data_simple['MACD'][index] > data_simple['signal_line'][index] and data_simple['signal_line'][index] > 0:\n",
    "                macd_rating=1\n",
    "            elif data_simple['signal_line'][index] > data_simple['MACD'][index] and data_simple['MACD'][index] > 0:\n",
    "                macd_rating=2\n",
    "            elif data_simple['MACD'][index] < 0 and 0 < data_simple['signal_line'][index]:\n",
    "                macd_rating=3\n",
    "            elif data_simple['MACD'][index] < data_simple['signal_line'][index] and data_simple['signal_line'][index]< 0:\n",
    "                macd_rating=4\n",
    "            elif data_simple['signal_line'][index] < data_simple['MACD'][index] and data_simple['MACD'][index] < 0:\n",
    "                macd_rating=5\n",
    "            elif data_simple['MACD'][index] > 0 and 0 > data_simple['signal_line'][index]:\n",
    "                macd_rating=6\n",
    "            macd_ratings.append(macd_rating)\n",
    "        return macd_ratings"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
